{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e4c7f8",
   "metadata": {},
   "source": [
    "# Data Test 1 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4c1499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  3.  4.  7.  8. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22.\n",
      " 23. 24. 25. 27. 28. 29. 30.]\n",
      "1.0\n",
      "MSE:  0.00023628072878945888\n",
      "R2:  0.9880901984316083\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "3.0\n",
      "MSE:  0.0005931066782442049\n",
      "R2:  0.9589235407562592\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "4.0\n",
      "MSE:  0.008714687504644696\n",
      "R2:  0.8797631797541201\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "7.0\n",
      "MSE:  0.010983667430287733\n",
      "R2:  0.48195878179156415\n",
      "[90.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "8.0\n",
      "MSE:  0.0006219513089584563\n",
      "R2:  0.9415583180514548\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "10.0\n",
      "MSE:  0.0008888432112126474\n",
      "R2:  0.9096205176080969\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "11.0\n",
      "MSE:  0.03338914473249038\n",
      "R2:  -5.142805832361615\n",
      "[182.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "12.0\n",
      "MSE:  0.0015991502788332097\n",
      "R2:  0.7024881051055936\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "13.0\n",
      "MSE:  0.0009307445119964082\n",
      "R2:  0.3372635911605939\n",
      "[3652.0]\n",
      "[365.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "14.0\n",
      "MSE:  0.0007492162519704876\n",
      "R2:  0.9065345907885112\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "15.0\n",
      "MSE:  0.08121007788833927\n",
      "R2:  0.4249611422878323\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "16.0\n",
      "MSE:  0.00023090033154540655\n",
      "R2:  0.9818670043816573\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "17.0\n",
      "MSE:  0.001555131831337531\n",
      "R2:  0.906143771770369\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "18.0\n",
      "MSE:  0.0022892119434000154\n",
      "R2:  -4.204290531322284\n",
      "[3652.0]\n",
      "[365.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "19.0\n",
      "MSE:  0.005752584895025171\n",
      "R2:  0.8439083839836279\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "20.0\n",
      "MSE:  0.0022564731870888576\n",
      "R2:  0.8278697401053304\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "21.0\n",
      "MSE:  0.011605428087903685\n",
      "R2:  0.332986720796532\n",
      "[90.0]\n",
      "[365.0]\n",
      "Quality metric (sum of introduced error):  0.15\n",
      "22.0\n",
      "MSE:  0.0006682567294865049\n",
      "R2:  0.9295195212722008\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "23.0\n",
      "MSE:  0.012307720668194112\n",
      "R2:  0.7054232594252308\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "24.0\n",
      "MSE:  0.0005530407509586546\n",
      "R2:  0.990398158591338\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "25.0\n",
      "MSE:  0.0010447619476373529\n",
      "R2:  0.8576072091635376\n",
      "[90.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "27.0\n",
      "MSE:  0.01479364764074478\n",
      "R2:  0.4119719209428083\n",
      "[30.0]\n",
      "[90.0]\n",
      "Quality metric (sum of introduced error):  0.069\n",
      "28.0\n",
      "MSE:  0.004603189417046639\n",
      "R2:  0.8715657700341275\n",
      "[30.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "29.0\n",
      "MSE:  0.0016340781378410818\n",
      "R2:  0.8142878714836344\n",
      "[90.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n",
      "30.0\n",
      "MSE:  0.012865721857858238\n",
      "R2:  -3.107861101935833\n",
      "[365.0]\n",
      "[30.0]\n",
      "Quality metric (sum of introduced error):  0\n"
     ]
    }
   ],
   "source": [
    "nb_rates = 9\n",
    "features = \"Saturation\"\n",
    "scale = \"BVE\"\n",
    "\n",
    "quality_metric_replication = []\n",
    "#for replication in range(1, nb_replication+1):\n",
    "data_no_na = retrieve_and_clean_data(nb_rates, features, scale)\n",
    "data_complete = extract_complete_data_for_BVE(data_no_na)\n",
    "sites_completes = data_complete.Site.unique()\n",
    "print(sites_completes)\n",
    "for site in sites_completes:\n",
    "    print(site)\n",
    "    data_train, data_test, training_cases, test_cases = retrieve_list_cases_and_pick_training_cases_BVE_one_case(data_complete, site)\n",
    "    #print(test_cases)\n",
    "    X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets_BVE(data_train, data_test)\n",
    "    forest = train_forest(X_train, y_train)\n",
    "    y_test_pred = forest.predict(X_test)\n",
    "    mse, r2 = compute_standard_metrics(y_test, y_test_pred)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"R2: \", r2)\n",
    "    data_test = update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, one_case=True)\n",
    "    p_reals, p_preds = extract_preals_and_ppreds_BVE(data_test, test_cases, nb_rates)\n",
    "    print(p_reals)\n",
    "    print(p_preds)\n",
    "    hreal_preals, hreal_ppreds, quality_metric = extract_hreal_for_preal_and_ppred_and_quality_metric_BVE(data_test, test_cases, p_reals, p_preds)\n",
    "    quality_metric_no_nan = [x for x in quality_metric if np.isnan(x) == False]\n",
    "    quality_metric_sum = round(sum(quality_metric_no_nan),3)\n",
    "    print(\"Quality metric (sum of introduced error): \", quality_metric_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9981de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b306a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171f9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import csv\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d88a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_clean_data(nb_rates, features, scale):\n",
    "    data = pd.read_csv(\"data/Input_Data/Input_Data_Complete_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale) + \"_Comparable.csv\", sep=\";\",\n",
    "        header=0)\n",
    "\n",
    "    data.replace(' ', np.nan, inplace=True)\n",
    "    data_no_na = data.dropna()\n",
    "\n",
    "    return data_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350f14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complete_data_for_BVE(data_no_na):\n",
    "    data_complete = pd.DataFrame(columns=data_no_na.columns)\n",
    "    sub_completes = {}\n",
    "    nb_sites = int(data_no_na[\"Site\"].max())\n",
    "    for site in range(1, nb_sites+1):\n",
    "        data_site_sub = data_no_na.loc[(data_no_na['Site'] == site)]\n",
    "    #if data_site_sub.empty:\n",
    "    #    continue\n",
    "        if len(data_site_sub) == nb_rates:\n",
    "            data_complete = pd.concat([data_complete, data_site_sub], sort=False)\n",
    "    return data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cba3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list_cases_and_pick_training_cases_BVE_one_case(data_complete, case):\n",
    "    sites_completes = data_complete.Site.unique()\n",
    "    #training_nb_cases = round((len(sites_completes) * 80)/100)\n",
    "    \n",
    "\n",
    "    #training_cases = random.sample(sites_completes.tolist(), len(sites_completes)-1)\n",
    "\n",
    "    #Build training data\n",
    "    #data_test = pd.DataFrame(columns=data_complete.columns)\n",
    "    data_test = data_complete.loc[(data_complete['Site'] == case)]\n",
    "    #    data_train = pd.concat([data_train, train], sort=False)\n",
    "    \n",
    "    #Build test data\n",
    "    training_cases = [x for x in sites_completes.tolist() if x not in [case]] + [x for x in [case] if x not in sites_completes.tolist()]\n",
    "    data_train = pd.DataFrame(columns=data_complete.columns)\n",
    "    for cas in training_cases:\n",
    "        train = data_complete.loc[(data_complete['Site'] == cas)]\n",
    "        data_train = pd.concat([data_train, train], sort=False)\n",
    "\n",
    "    return data_train, data_test, training_cases, [case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40349aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_outputs_datasets_BVE(data_train, data_test):\n",
    "    y_train = data_train.filter([\"Site\", \"H Error\"], axis=1)\n",
    "    X_train = data_train.drop(\"H Error\", axis=1)\n",
    "    del y_train[\"Site\"]\n",
    "    del X_train[\"Site\"]\n",
    "\n",
    "    y_test = data_test.filter([\"Site\", \"H Error\"], axis=1)\n",
    "    X_test = data_test.drop(\"H Error\", axis=1)\n",
    "    del y_test[\"Site\"]\n",
    "    del X_test[\"Site\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3670598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(X_train, y_train):\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=1000, criterion=\"mse\", random_state=1, n_jobs=-1, oob_score = True, bootstrap = True\n",
    "    )\n",
    "    forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba5367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_metrics(y_test, y_test_pred):\n",
    "\n",
    "    mse = mean_squared_error(y_test.values.ravel(), y_test_pred)\n",
    "    r2 = r2_score(y_test.values.ravel(), y_test_pred)\n",
    "\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab674a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, one_case=False):\n",
    "    suffixe = \"_\".join(map(str,list(map(int, training_cases))))\n",
    "    if one_case:\n",
    "        suffixe += \"_OneCase\"\n",
    "    data_test = data_test.assign(Htest=y_test.values.ravel())\n",
    "    data_test = data_test.assign(HtestPred=y_test_pred)\n",
    "    data_test.to_csv(\"data/Output_Data/Data_Test_With_Htest_pred_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale)  + \"_\" + str(suffixe) + \".csv\", index=False, sep=\";\")\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aabfe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_preals_and_ppreds_BVE(data_test, test_cases, nb_rates):\n",
    "    p_reals = []\n",
    "    p_preds = []\n",
    "    threshold = 0.1\n",
    "    for case in test_cases:\n",
    "        test = data_test.loc[(data_test['Site'] == case)]\n",
    "        htest_valid = True\n",
    "        htestpred_valid = True\n",
    "        preal = 0\n",
    "        ppred = 0\n",
    "        for i_rate in range(nb_rates):\n",
    "            #print(test)\n",
    "            htest = test[\"Htest\"].tolist()[i_rate]\n",
    "            htest_pred = test[\"HtestPred\"].tolist()[i_rate]\n",
    "            if (float(htest) > threshold) & (htest_valid):\n",
    "                htest_valid = False\n",
    "                preal = test[\"Rate\"].tolist()[i_rate-1]\n",
    "                p_reals.append(preal)\n",
    "            if (float(htest_pred) > threshold) & (htestpred_valid):\n",
    "                htestpred_valid = False\n",
    "                ppred = test[\"Rate\"].tolist()[i_rate-1]\n",
    "                p_preds.append(ppred)\n",
    "            if (i_rate == nb_rates-1) & htest_valid:\n",
    "                preal = test[\"Rate\"].tolist()[i_rate]\n",
    "                p_reals.append(preal)\n",
    "            if (i_rate == nb_rates-1) & htestpred_valid:\n",
    "                ppred = test[\"Rate\"].tolist()[i_rate]\n",
    "                p_preds.append(ppred)\n",
    "\n",
    "    return p_reals, p_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceca3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hreal_for_preal_and_ppred_and_quality_metric_BVE(data_test, test_cases, p_reals, p_preds):\n",
    "    hreal_preals = []\n",
    "    hreal_ppreds = []\n",
    "    quality_metric = []\n",
    "    for i_case in range(len(test_cases)):\n",
    "        d_preal = data_test.loc[(data_test['Site'] == test_cases[i_case]) & (data_test['Rate'] == p_reals[i_case])]\n",
    "        hreal_preal = d_preal[\"H Error\"]\n",
    "        d_ppred = data_test.loc[(data_test['Site'] == test_cases[i_case])  & (data_test['Rate'] == p_preds[i_case])]\n",
    "        hreal_ppred = d_ppred[\"H Error\"]\n",
    "        #print(hreal_preal, hreal_ppred)\n",
    "        hreal_preals.append(float(hreal_preal))\n",
    "        hreal_ppreds.append(float(hreal_ppred))\n",
    "        if p_preds[i_case] > p_reals[i_case]:\n",
    "            quality_metric.append(float(hreal_ppred)-float(hreal_preal))\n",
    "        else:\n",
    "            quality_metric.append(np.nan)\n",
    "\n",
    "    return hreal_preals, hreal_ppreds, quality_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916a58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b17c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7c4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cd39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import csv\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f428ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_clean_data(nb_rates, features, scale):\n",
    "    data = pd.read_csv(\"data/Input_Data/Input_Data_Complete_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale) + \"_Comparable.csv\", sep=\";\",\n",
    "        header=0)\n",
    "\n",
    "    data.replace(' ', np.nan, inplace=True)\n",
    "    data_no_na = data.dropna()\n",
    "\n",
    "    return data_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1465f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nb_sites_and_subs(data_no_na):\n",
    "    nb_sites = data_no_na[\"Site\"].max()\n",
    "    # Number of subcatch per site\n",
    "    nb_subs = {}\n",
    "    for site_number in range(1, nb_sites+1):\n",
    "        nb_sub = data_no_na[data_no_na[\"Site\"]==site_number]['SubCatch'].max()\n",
    "        if pd.isna(nb_sub):\n",
    "            continue\n",
    "        nb_subs[site_number] = nb_sub\n",
    "    \n",
    "    return nb_sites, nb_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ff8953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complete_data(data_no_na, nb_subs, nb_rates):\n",
    "    # Build data with data for all 30 rates\n",
    "    data_complete = pd.DataFrame(columns=data_no_na.columns)\n",
    "    sub_completes = {}\n",
    "    for site in nb_subs.keys():\n",
    "        for sub in range(1, int(nb_subs[site])+1):\n",
    "            data_site_sub = data_no_na.loc[(data_no_na['Site'] == site) & (data_no_na['SubCatch'] == sub)]\n",
    "            if data_site_sub.empty:\n",
    "                continue\n",
    "            if len(data_site_sub) == nb_rates:\n",
    "                data_complete = pd.concat([data_complete, data_site_sub], sort=False)\n",
    "                #print(sub_completes[site].empty)\n",
    "                if site in sub_completes.keys():\n",
    "                    sub_completes[site].append(sub)\n",
    "                else:\n",
    "                    sub_completes[site] = [sub]\n",
    "    data_complete.to_csv(\"data/Data_Input_Sub_Complete_Rate_test.csv\", index=False, sep=\";\")\n",
    "\n",
    "    return data_complete, sub_completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "977bcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subs_into_training_test_datasets(sub_completes):\n",
    "# Get number of subcatch for the split of data training / test : 80 / 20\n",
    "    nb_subs_complete = 0\n",
    "    for site in sub_completes:\n",
    "        nb_subs_complete += len(sub_completes[site])\n",
    "    training_nb_sub = round((nb_subs_complete * 80)/100)\n",
    "\n",
    "    lst_couple_site_sub = []\n",
    "    for site in sub_completes:\n",
    "        for sub in sub_completes[site]:\n",
    "            lst_couple_site_sub.append([site, sub])\n",
    "\n",
    "    return training_nb_sub, lst_couple_site_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d2a5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_and_test_datasets(data_complete, lst_couple_site_sub, training_nb_sub):\n",
    "    # Build training dataset\n",
    "    training_couples = random.sample(lst_couple_site_sub, training_nb_sub)\n",
    "    data_train = pd.DataFrame(columns=data_complete.columns)\n",
    "    for couple in training_couples:\n",
    "        train = data_complete.loc[(data_complete['Site'] == couple[0]) & (data_complete['SubCatch'] == couple[1])]\n",
    "        data_train = pd.concat([data_train, train], sort=False)\n",
    "\n",
    "    # Build Testing dataset\n",
    "    test_couples = [x for x in lst_couple_site_sub if x not in training_couples] + [x for x in training_couples if x not in lst_couple_site_sub]\n",
    "    data_test = pd.DataFrame(columns=data_complete.columns)\n",
    "    for couple in test_couples:\n",
    "        test = data_complete.loc[(data_complete['Site'] == couple[0]) & (data_complete['SubCatch'] == couple[1])]\n",
    "        data_test = pd.concat([data_test, test], sort=False)\n",
    "\n",
    "    return data_train, data_test, training_couples, test_couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7100d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_outputs_datasets(data_train, data_test):\n",
    "    y_train = data_train.filter([\"Site\", \"SubCatch\", \"H Error\"], axis=1)\n",
    "    X_train = data_train.drop(\"H Error\", axis=1)\n",
    "    del y_train[\"Site\"]\n",
    "    del y_train[\"SubCatch\"]\n",
    "    del X_train[\"Site\"]\n",
    "    del X_train[\"SubCatch\"]\n",
    "\n",
    "    y_test = data_test.filter([\"Site\", \"SubCatch\", \"H Error\"], axis=1)\n",
    "    X_test = data_test.drop(\"H Error\", axis=1)\n",
    "    del y_test[\"Site\"]\n",
    "    del y_test[\"SubCatch\"]\n",
    "    del X_test[\"Site\"]\n",
    "    del X_test[\"SubCatch\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4194e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(X_train, y_train):\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=1000, criterion=\"mse\", random_state=1, n_jobs=-1, oob_score = True, bootstrap = True\n",
    "    )\n",
    "    forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "625f7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_metrics(y_test, y_test_pred):\n",
    "\n",
    "    mse = mean_squared_error(y_test.values.ravel(), y_test_pred)\n",
    "    r2 = r2_score(y_test.values.ravel(), y_test_pred)\n",
    "\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2866f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, scale, one_case=False):\n",
    "    #suffixe = \"_\".join(map(str,list(map(int, training_cases))))\n",
    "    suffixe = \"\"\n",
    "    if scale == \"BVE\":\n",
    "        suffixe = \"_\".join(map(str,list(map(int, training_cases))))\n",
    "    if one_case:\n",
    "        suffixe += \"_OneCase\"\n",
    "    data_test = data_test.assign(Htest=y_test.values.ravel())\n",
    "    data_test = data_test.assign(HtestPred=y_test_pred)\n",
    "    data_test.to_csv(\"data/Output_Data/Data_Test_With_Htest_pred_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale)  + \"_\" + str(suffixe) + \".csv\", index=False, sep=\";\")\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68f33b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_preals_and_ppreds(data_test, test_couples, nb_rates):\n",
    "    p_reals = []\n",
    "    p_preds = []\n",
    "    threshold = 0.1\n",
    "    for couple in test_couples:\n",
    "        print(\"couple: \", couple[0], couple[1])\n",
    "        test = data_test.loc[(data_test['Site'] == int(couple[0])) & (data_test['SubCatch'] == couple[1])]\n",
    "        #print(test)\n",
    "        htest_valid = True\n",
    "        htestpred_valid = True\n",
    "        preal = 0\n",
    "        ppred = 0\n",
    "        for i_rate in range(nb_rates):\n",
    "            #print(\"i_rate\", i_rate)\n",
    "            htest = test[\"Htest\"].tolist()[i_rate]\n",
    "            htest_pred = test[\"HtestPred\"].tolist()[i_rate]\n",
    "            if (float(htest) > threshold) & (htest_valid):\n",
    "                htest_valid = False\n",
    "                preal = test[\"Rate\"].tolist()[i_rate-1]\n",
    "                p_reals.append(preal)\n",
    "            if (float(htest_pred) > threshold) & (htestpred_valid):\n",
    "                htestpred_valid = False\n",
    "                ppred = test[\"Rate\"].tolist()[i_rate-1]\n",
    "                p_preds.append(ppred)\n",
    "            if (i_rate == nb_rates-1) & htest_valid:\n",
    "                preal = test[\"Rate\"].tolist()[i_rate]\n",
    "                p_reals.append(preal)\n",
    "            if (i_rate == nb_rates-1) & htestpred_valid:\n",
    "                ppred = test[\"Rate\"].tolist()[i_rate]\n",
    "                p_preds.append(ppred)\n",
    "\n",
    "    return p_reals, p_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b4744e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hreal_for_preal_and_ppred_and_quality_metric(data_test, test_couples, p_reals, p_preds):\n",
    "    hreal_preals = []\n",
    "    hreal_ppreds = []\n",
    "    quality_metric = []\n",
    "    for i_sub in range(len(test_couples)):\n",
    "        d_preal = data_test.loc[(data_test['Site'] == test_couples[i_sub][0]) & (data_test['SubCatch'] == test_couples[i_sub][1]) & (data_test['Rate'] == p_reals[i_sub])]\n",
    "        hreal_preal = d_preal[\"H Error\"]\n",
    "        d_ppred = data_test.loc[(data_test['Site'] == test_couples[i_sub][0]) & (data_test['SubCatch'] == test_couples[i_sub][1]) & (data_test['Rate'] == p_preds[i_sub])]\n",
    "        hreal_ppred = d_ppred[\"H Error\"]\n",
    "        #print(hreal_preal, hreal_ppred)\n",
    "        hreal_preals.append(float(hreal_preal))\n",
    "        hreal_ppreds.append(float(hreal_ppred))\n",
    "        if p_preds[i_sub] > p_reals[i_sub]:\n",
    "            quality_metric.append(float(hreal_ppred)-float(hreal_preal))\n",
    "        else:\n",
    "            quality_metric.append(np.nan)\n",
    "\n",
    "    return hreal_preals, hreal_ppreds, quality_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf11a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics(test_cases, training_cases, sites_completes, mse, r2, quality_metric, quality_metric_sum, p_reals, p_preds, hreal_preals, hreal_ppreds, scale, one_case=False):\n",
    "    suffixe = \"\"\n",
    "    if scale == \"BVE\":\n",
    "        suffixe = \"_\".join(map(str,list(map(int, training_cases))))\n",
    "    if one_case:\n",
    "        suffixe += \"_OneCase\"\n",
    "    MYDIR = \"data/Output_Data\"\n",
    "    with open(\n",
    "        MYDIR\n",
    "        + \"/\"\n",
    "        + \"Prediction_data_complete_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale) + \"_\" + str(suffixe) + \".csv\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        writer.writerow(\n",
    "            [\n",
    "                \"Site\",\n",
    "                \"SubCatch\",\n",
    "                \"Number Data Training\",\n",
    "                \"Number Global Data\",\n",
    "                \"MSE Test\",\n",
    "                \"R2 Test\",\n",
    "                \"Quality Metric\",\n",
    "                \"Quality Sum\",\n",
    "                \"P Real\",\n",
    "                \"P pred\",\n",
    "                \"H Real Preal\",\n",
    "                \"H Real Ppred\"\n",
    "            ]\n",
    "        )\n",
    "        for ind in range(len(test_cases)):\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    test_cases[ind][0],\n",
    "                    test_cases[ind][1],\n",
    "                    len(training_cases),\n",
    "                    len(sites_completes),\n",
    "                    mse,\n",
    "                    r2,\n",
    "                    quality_metric[ind],\n",
    "                    quality_metric_sum,\n",
    "                    p_reals[ind],\n",
    "                    p_preds[ind],\n",
    "                    hreal_preals[ind],\n",
    "                    hreal_ppreds[ind]\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6e3bcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.05718358215662917\n",
      "R2:  0.3583413632296427\n",
      "couple:  2 2\n",
      "couple:  33 6\n",
      "couple:  33 9\n",
      "couple:  35 8\n",
      "couple:  35 11\n",
      "couple:  37 9\n",
      "couple:  38 7\n",
      "couple:  39 4\n",
      "couple:  39 5\n",
      "Quality metric (sum of introduced error):  0.078\n"
     ]
    }
   ],
   "source": [
    "nb_rates =  9\n",
    "features = \"Geomorph\"\n",
    "scale = \"SUB\"\n",
    "data_no_na = retrieve_and_clean_data(nb_rates, features, scale)\n",
    "#print(data_no_na)\n",
    "nb_sites, nb_subs =  extract_nb_sites_and_subs(data_no_na)\n",
    "#print(nb_sites, nb_subs)\n",
    "data_complete, sub_completes = extract_complete_data(data_no_na, nb_subs, nb_rates)\n",
    "#print(sub_completes)\n",
    "training_nb_sub, lst_couple_site_sub = split_subs_into_training_test_datasets(sub_completes)\n",
    "#print(training_nb_sub, len(lst_couple_site_sub))\n",
    "data_train, data_test, training_cases, test_cases = build_training_and_test_datasets(data_complete, lst_couple_site_sub, training_nb_sub)\n",
    "#print(data_train)\n",
    "X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets(data_train, data_test)\n",
    "forest = train_forest(X_train, y_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "mse, r2 = compute_standard_metrics(y_test, y_test_pred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"R2: \", r2)\n",
    "#print(training_cases)\n",
    "data_test = update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, scale, one_case=False)\n",
    "#print(test_cases)\n",
    "#print(data_test.loc[(data_test['Site'] == 19)])\n",
    "#print(data_test.loc[(data_test['Site'] == 19) & (data_test['SubCatch'] == 1)])\n",
    "\n",
    "p_reals, p_preds = extract_preals_and_ppreds(data_test, test_cases, nb_rates)\n",
    "#print(p_reals, p_preds)\n",
    "hreal_preals, hreal_ppreds, quality_metric = extract_hreal_for_preal_and_ppred_and_quality_metric(data_test, test_cases, p_reals, p_preds)\n",
    "#print(hreal_preals, hreal_ppreds)\n",
    "#print(quality_metric)\n",
    "quality_metric_no_nan = [x for x in quality_metric if np.isnan(x) == False]\n",
    "quality_metric_sum = round(sum(quality_metric_no_nan),3)\n",
    "print(\"Quality metric (sum of introduced error): \", quality_metric_sum)\n",
    "quality_metric = [0 if x != x else x for x in quality_metric]\n",
    "store_metrics(test_cases, training_cases, lst_couple_site_sub, mse, r2, quality_metric, quality_metric_sum, p_reals, p_preds, hreal_preals, hreal_ppreds, scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ac02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd392c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_clean_data(nb_rates, features, scale):\n",
    "    data = pd.read_csv(\"data/Input_Data/Input_Data_Complete_Rates_\" + str(nb_rates) + \"_Features_\" + str(features) + \"_\" + str(scale) + \"_Comparable.csv\", sep=\";\",\n",
    "        header=0)\n",
    "\n",
    "    data.replace(' ', np.nan, inplace=True)\n",
    "    data_no_na = data.dropna()\n",
    "\n",
    "    return data_no_na\n",
    "\n",
    "def extract_nb_sites_and_subs(data_no_na):\n",
    "    nb_sites = data_no_na[\"Site\"].max()\n",
    "    # Number of subcatch per site\n",
    "    nb_subs = {}\n",
    "    for site_number in range(1, nb_sites+1):\n",
    "        nb_sub = data_no_na[data_no_na[\"Site\"]==site_number]['SubCatch'].max()\n",
    "        if pd.isna(nb_sub):\n",
    "            continue\n",
    "        nb_subs[site_number] = nb_sub\n",
    "\n",
    "    return nb_sites, nb_subs\n",
    "\n",
    "def extract_complete_data(data_no_na, nb_subs, nb_rates):\n",
    "    # Build data with data for all 30 rates\n",
    "    data_complete = pd.DataFrame(columns=data_no_na.columns)\n",
    "    sub_completes = {}\n",
    "    for site in nb_subs.keys():\n",
    "        for sub in range(1, int(nb_subs[site])+1):\n",
    "            data_site_sub = data_no_na.loc[(data_no_na['Site'] == site) & (data_no_na['SubCatch'] == sub)]\n",
    "            if data_site_sub.empty:\n",
    "                continue\n",
    "            if len(data_site_sub) == nb_rates:\n",
    "                data_complete = pd.concat([data_complete, data_site_sub], sort=False)\n",
    "                #print(sub_completes[site].empty)\n",
    "                if site in sub_completes.keys():\n",
    "                    sub_completes[site].append(sub)\n",
    "                else:\n",
    "                    sub_completes[site] = [sub]\n",
    "    #data_complete.to_csv(\"data/Data_Input_Sub_Complete_Rate_test.csv\", index=False, sep=\";\")\n",
    "\n",
    "    return data_complete, sub_completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3d502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2624005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3ac00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af58018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Site  SubCatch  Rate   H Error     Slope   Elevation          LC  \\\n",
      "0       2       1.0     1  0.000000  2.035973   29.159981  769.298091   \n",
      "1       2       1.0     2  0.003549  2.035973   29.159981  769.298091   \n",
      "2       2       1.0     7  0.014516  2.035973   29.159981  769.298091   \n",
      "3       2       1.0    30  0.037876  2.035973   29.159981  769.298091   \n",
      "4       2       1.0    90  0.091119  2.035973   29.159981  769.298091   \n",
      "..    ...       ...   ...       ...       ...         ...         ...   \n",
      "418    39       7.0    90  0.076823  4.720726  195.869247  672.920859   \n",
      "419    39       7.0   182  0.000076  4.720726  195.869247  672.920859   \n",
      "420    39       7.0   365  0.193669  4.720726  195.869247  672.920859   \n",
      "421    39       7.0   730  0.000076  4.720726  195.869247  672.920859   \n",
      "422    39       7.0  3652  0.274814  4.720726  195.869247  672.920859   \n",
      "\n",
      "          SAR     Area  \n",
      "0    1.000434  9635625  \n",
      "1    1.000434  9635625  \n",
      "2    1.000434  9635625  \n",
      "3    1.000434  9635625  \n",
      "4    1.000434  9635625  \n",
      "..        ...      ...  \n",
      "418  1.001445  1299375  \n",
      "419  1.001445  1299375  \n",
      "420  1.001445  1299375  \n",
      "421  1.001445  1299375  \n",
      "422  1.001445  1299375  \n",
      "\n",
      "[423 rows x 9 columns]\n",
      "39 {2: 4.0, 13: 1.0, 18: 4.0, 19: 2.0, 33: 9.0, 35: 13.0, 37: 12.0, 38: 9.0, 39: 9.0}\n",
      "{2: [1, 2, 3, 4], 13: [1], 18: [4], 19: [1, 2], 33: [2, 3, 6, 7, 8, 9], 35: [4, 5, 6, 7, 8, 9, 11, 12, 13], 37: [2, 3, 4, 5, 6, 7, 8, 9, 12], 38: [1, 2, 3, 5, 6, 7, 8, 9], 39: [2, 3, 4, 5, 7, 8, 9]}\n",
      "[[2, 1], [2, 2], [2, 3], [2, 4], [13, 1], [18, 4], [19, 1], [19, 2], [33, 2], [33, 3], [33, 6], [33, 7], [33, 8], [33, 9], [35, 4], [35, 5], [35, 6], [35, 7], [35, 8], [35, 9], [35, 11], [35, 12], [35, 13], [37, 2], [37, 3], [37, 4], [37, 5], [37, 6], [37, 7], [37, 8], [37, 9], [37, 12], [38, 1], [38, 2], [38, 3], [38, 5], [38, 6], [38, 7], [38, 8], [38, 9], [39, 2], [39, 3], [39, 4], [39, 5], [39, 7], [39, 8], [39, 9]]\n",
      "Selected sites:  [[39, 2], [19, 2], [2, 2], [35, 7], [35, 5], [35, 4], [33, 2], [19, 1], [38, 3], [18, 4]]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import csv\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "nb_rates = 9\n",
    "features = \"Geomorph\"\n",
    "scale = \"SUB\"\n",
    "size_data = 10\n",
    "\n",
    "quality_metric_replication = []\n",
    "data_no_na = retrieve_and_clean_data(nb_rates, features, scale)\n",
    "print(data_no_na)\n",
    "nb_sites, nb_subs =  extract_nb_sites_and_subs(data_no_na)\n",
    "print(nb_sites, nb_subs)\n",
    "data_complete, sub_completes = extract_complete_data(data_no_na, nb_subs, nb_rates)\n",
    "print(sub_completes)\n",
    "lst_couple_site_sub = []\n",
    "for site in sub_completes:\n",
    "    for sub in sub_completes[site]:\n",
    "        lst_couple_site_sub.append([site, sub])\n",
    "\n",
    "print(lst_couple_site_sub)\n",
    "for replication in range(1, nb_replication+1):\n",
    "        print(\"Replication: \", replication)\n",
    "    lst_reduced_cases = reduce_size_BVE(lst_couple_site_sub, size_data)\n",
    "    for case in lst_reduced_cases:\n",
    "        training_nb_sub = 1\n",
    "        data_train, data_test, training_cases, test_cases = retrieve_list_cases_and_pick_training_cases_SUB_one_case(data_complete, case, lst_couple_site_sub)    \n",
    "\n",
    "        X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets_SUB(data_train, data_test)\n",
    "#print(X_train, y_train)\n",
    "        forest = train_forest(X_train, y_train)\n",
    "        y_test_pred = forest.predict(X_test)\n",
    "        mse, r2 = compute_standard_metrics(y_test, y_test_pred)\n",
    "        print(\"MSE: \", mse)\n",
    "        print(\"R2: \", r2)\n",
    "#print(training_cases)\n",
    "        data_test = update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, scale, size_data, one_case=True)\n",
    "\n",
    "\n",
    "        p_reals, p_preds = extract_preals_and_ppreds(data_test, test_cases, nb_rates)\n",
    "        print(p_reals, p_preds)\n",
    "        hreal_preals, hreal_ppreds, quality_metric = extract_hreal_for_preal_and_ppred_and_quality_metric(data_test, test_cases, p_reals, p_preds)\n",
    "        print(hreal_preals, hreal_ppreds)\n",
    "        print(quality_metric)\n",
    "        quality_metric_no_nan = [x for x in quality_metric if np.isnan(x) == False]\n",
    "        quality_metric_sum = round(sum(quality_metric_no_nan),3)\n",
    "        print(\"Quality metric (sum of introduced error): \", quality_metric_sum)\n",
    "        quality_metric = [0 if x != x else x for x in quality_metric]\n",
    "        store_metrics(test_cases, training_cases, lst_couple_site_sub, mse, r2, quality_metric, quality_metric_sum, p_reals, p_preds, hreal_preals, hreal_ppreds, scale, size_data, one_case=True)\n",
    "        quality_metric_replication.append(quality_metric_sum)\n",
    "store_metrics_replication(quality_metric_replication, nb_replication, nb_rates, features, scale, size_data, one_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "627a252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_size_BVE(lst_couple_site_sub, size_data):\n",
    "    if (size_data is not None) and (len(lst_couple_site_sub) > size_data):\n",
    "        selected_sites = random.sample(lst_couple_site_sub, size_data)\n",
    "        print(\"Selected sites: \", selected_sites)\n",
    "        #input_data = pd.DataFrame(columns=data_complete.columns)\n",
    "        #for site in selected_sites:\n",
    "            #data_site = data_complete.loc[(data_complete['Site'] == site)]\n",
    "            #input_data = pd.concat([input_data, data_site], sort=False)\n",
    "        #print(input_data)\n",
    "        #return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BVE\n",
    "quality_metric_replication = []\n",
    "    #for replication in range(1, nb_replication+1):\n",
    "    data_no_na = retrieve_and_clean_data(nb_rates, features, scale)\n",
    "    data_complete = extract_complete_data_for_BVE(data_no_na, nb_rates)\n",
    "    for replication in range(1, nb_replication+1):\n",
    "        print(\"Replication: \", replication)\n",
    "        input_data = reduce_size(data_complete, size_data)\n",
    "        sites_completes = input_data.Site.unique()\n",
    "        print(sites_completes)\n",
    "        for site in sites_completes:\n",
    "            data_train, data_test, training_cases, test_cases = retrieve_list_cases_and_pick_training_cases_BVE_one_case(data_complete, site)\n",
    "            X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets_BVE(data_train, data_test)\n",
    "            forest = train_forest(X_train, y_train)\n",
    "            y_test_pred = forest.predict(X_test)\n",
    "            mse, r2 = compute_standard_metrics(y_test, y_test_pred)\n",
    "            print(\"MSE: \", mse)\n",
    "            print(\"R2: \", r2)\n",
    "            data_test = update_and_store_data_with_h_pred(data_test, y_test, y_test_pred, training_cases, scale, size_data, one_case=True)\n",
    "            p_reals, p_preds = extract_preals_and_ppreds_BVE(data_test, test_cases, nb_rates)\n",
    "            # print(p_reals)\n",
    "            # print(p_preds)\n",
    "            hreal_preals, hreal_ppreds, quality_metric = extract_hreal_for_preal_and_ppred_and_quality_metric_BVE(data_test, test_cases, p_reals, p_preds)\n",
    "            # print(hreal_preals)\n",
    "            # print(hreal_ppreds)\n",
    "            quality_metric_no_nan = [x for x in quality_metric if np.isnan(x) == False]\n",
    "            quality_metric_sum = round(sum(quality_metric_no_nan),3)\n",
    "            print(\"Quality metric (sum of introduced error): \", quality_metric_sum)\n",
    "            store_metrics_BVE(test_cases, training_cases, data_complete.Site.unique(), mse, r2, quality_metric, quality_metric_sum, p_reals, p_preds, hreal_preals, hreal_ppreds, scale, size_data, one_case=True)\n",
    "            quality_metric_replication.append(quality_metric_sum)\n",
    "    store_metrics_replication(quality_metric_replication, nb_replication, nb_rates, features, scale, size_data, one_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc41ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
